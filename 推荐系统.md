# 问题规划
假设你是一个电影供应商,你发布电影并让观众对其打分,以下表格是观众的打分情况


|Movie|Alice(1)|Bob(2)|Carol(3)|Dave(4)|
|---|---|---|---|---|
Love at last|5|5|0|0|
Romance forever|5|?|?|0|
Cute puppies of love|?|4|0|?|
Nonstop car chases|0|0|5|4|
Sword vs. karate|0|0|5|?|

前三部是爱情片,后三部是动作片.?表示该用户没有给该影片打分.

引入一些符号:

$n_u$表示用户的数量,这里等于4

$n_m$表示电影的数量,这里等于5

$r(i,j)$表示用户是否第$i$个用户是否给第$j$部电影评过分,1表示评过

$y^{(i,j)}$表示第$i$个用户给第$j$部电影的评分,仅在$r(i,j)=1$时有定义

# 基于内容的推荐系统
在上例中,我们假设每部电影有两个特征.$x_1$表示浪漫程度,$x_2$表示动作程度.

|Movie|Alice(1)|Bob(2)|Carol(3)|Dave(4)|$\underset{\text{(romance)}}{x_1}$|$\underset{\text{(action)}}{x_2}$|
|---|---|---|---|---|---|---|
Love at last|5|5|0|0|0.9|0|
Romance forever|5|?|?|0|1.0|0.01|
Cute puppies of love|?|4|0|?|0.99|0|
Nonstop car chases|0|0|5|4|0.1|1.0|
Sword vs. karate|0|0|5|?|0|0.9|

这样每部电影都有一个特征向量,如$x^{(1)}=[0.9\quad0]$

加入我们使用线性回归模型,用$\theta^{(j)}$表示用户$j$的参数,用$x^{(i)}$表示电影$i$的特征.那么对于用户$j$和电影$i$,我们的预测为
$$
(\theta^{(j)})^Tx^{(i)}
$$

针对用户$j$,我们要做的是
$$
\underset{\theta^{(j)}}{min}\frac{1}{2}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{k=1}^n(\theta_k^{(j)})^2
$$

公式中本应该有的$m$影响不大,将其删去.

上式只是对一个用户的学习,为了学习所有用户,可以写成
$$
\underset{\theta^{(1)},\cdots,\theta^{(n_u)}}{min}\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(\theta_k^{(j)})^2
$$

用梯度下降法求解的公式为
$$
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}(\text{for }k=0)\\
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda\theta_k^{(j)})(\text{for }k\neq0)\\
$$

# 协同过滤
之前我们提到根据已知的电影特征,可以训练出用户参数.相反地,根据已知的用户参数,我们也可以训练出电影特征.
$$
\underset{x^{(1)},\cdots,x^{(n_m)}}{min}\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^n(x_k^{(i)})^2
$$

这样,我们可以同时更新$x$和$\theta$
$$
J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^n(x_k^{(i)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(\theta_k^{(j)})^2
$$

梯度下降法的公式为
$$
x_k^{(i)}:=x_k^{(i)}-\alpha(\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})\theta_k^{(j)}+\lambda x_k^{(i)})\\
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda\theta_k^{(j)})
$$

协同过滤算法使用步骤如下：
1.  初始$x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)}$为一些随机小值
2.  使用梯度下降算法最小化代价函数
3.  在训练完算法后，我们预测$(\theta^{(j)})^Tx^{(i)}$为用户$j$给电影$i$的评分

同时也可以用于给用户推荐电影,例如，如果一位用户正在观看电影$x^{(i)}$，我们可以寻找另一部电影$x^{(j)}$，依据两部电影的特征向量之间的距离$||x^{(i)}-x^{(j)}||$的大小。

# 向量化：低秩矩阵分解
这是我的数据集
|Movie|Alice(1)|Bob(2)|Carol(3)|Dave(4)|
|---|---|---|---|---|
Love at last|5|5|0|0|
Romance forever|5|?|?|0|
Cute puppies of love|?|4|0|?|
Nonstop car chases|0|0|5|4|
Sword vs. karate|0|0|5|?|

将他们写入矩阵
$$
Y=
\begin{bmatrix}
5&5&0&0\\
5&?&?&0\\
?&4&0&?\\
0&0&5&4\\
0&0&5&?\\
\end{bmatrix}
$$

预测结果可以写成
$$
\begin{bmatrix}
(\theta^{(1)})^T(x^{(1)})& (\theta^{(2)})^T(x^{(1)})&\cdots&(\theta^{(n_u)})^T(x^{(1)}) \\
(\theta^{(1)})^T(x^{(2)})& (\theta^{(2)})^T(x^{(2)})&\cdots&(\theta^{(n_u)})^T(x^{(2)}) \\
\vdots&\vdots&\vdots&\vdots\\
(\theta^{(1)})^T(x^{(n_m)})& (\theta^{(2)})^T(x^{(n_m)})&\cdots&(\theta^{(n_u)})^T(x^{(n_m)}) \\
\end{bmatrix}
$$

可以将$x$和$\theta$写成矩阵的形式
$$
X=
\begin{bmatrix}
-(x^{(1)})^T-\\
-(x^{(2)})^T-\\
\vdots\\
-(x^{(n_m)})^T-\\
\end{bmatrix}
,
\Theta=
\begin{bmatrix}
-(\theta^{(1)})^T-\\
-(\theta^{(2)})^T-\\
\vdots\\
-(\theta^{(n_u)})^T-\\
\end{bmatrix}
$$

那么预测结果就可以写成$X\Theta^T$,这就是低秩矩阵分解.

# 均值归一化
如果我们新增一个用户 Eve，并且 Eve 没有为任何电影评分，那么我们以什么为依据为 Eve 推荐电影呢？

|Movie|Alice(1)|Bob(2)|Carol(3)|Dave(4)|Eve(5)|
|---|---|---|---|---|---|
Love at last|5|5|0|0|?|
Romance forever|5|?|?|0|?|
Cute puppies of love|?|4|0|?|?|
Nonstop car chases|0|0|5|4|?|
Sword vs. karate|0|0|5|?|?|

我们首先需要对结果$Y$矩阵进行均值归一化处理，将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值

$$
Y=\begin{bmatrix}
5&5&0&0&?\\
5&?&?&0&?\\
?&4&0&?&?\\
0&0&5&4&?\\
0&0&5&0&?\\
\end{bmatrix}
\quad
\mu=
\begin{bmatrix}
2.5\\
2.5\\
2\\
2.25\\
1.25\\
\end{bmatrix}
\rightarrow
Y=
\begin{bmatrix}
2.5&2.5&-2.5&-2.5&?\\
2.5&?&?&-2.5&?\\
?&2&-2&?&?\\
-2.25&-2.25&2.75&1.75&?\\
-1.25&-1.25&3.75&-1.25&?\\
\end{bmatrix}
$$

然后我们利用这个新的$Y$矩阵来训练算法。 如果我们要用新训练出的算法来预测评分，则需要将平均值重新加回去，预测$(\theta^{(j)})^Tx^{(i)}+\mu_i$,对于 Eve，我们的新模型会认为她给每部电影的评分都是该电影的平均分。